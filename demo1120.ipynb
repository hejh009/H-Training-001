{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac817af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d871a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid函数在x=0处的值为: 0.5\n",
      "Sigmoid函数在x=0处的导数为: 0.25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 自定义实现Sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# 定义输入张量x，设置requires_grad=True以便计算导数\n",
    "x = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "# 计算Sigmoid函数在x处的值\n",
    "y = sigmoid(x)\n",
    "\n",
    "# 计算Sigmoid函数在x处的导数\n",
    "y.backward()\n",
    "\n",
    "# 输出Sigmoid函数在x=0处的值和导数\n",
    "print(\"Sigmoid函数在x=0处的值为:\", y.item())\n",
    "print(\"Sigmoid函数在x=0处的导数为:\", x.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83c9f96b-70ff-47f9-8d9b-f1042ff50875",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "v5 = 3*v4\n",
    "v6 = v5 + v4 +1\n",
    "node_dict = {\"v1\": v1, \"v2\": v2, \"v3\": v3,'v4':v4,'v5':v5,'v6':v6}\n",
    "var_dict = {\"x1\": x1, \"x2\": x2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "703c0f8e-3732-4df3-bdab-c89a0c855a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "539d647d-4514-4475-8a7a-9b3d67aed2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点v1对x1导数:  tensor(1.)\n",
      "节点v1对x2导数:  tensor(0.)\n",
      "节点v2对x1导数:  tensor(0.)\n",
      "节点v2对x2导数:  tensor(1.)\n",
      "节点v3对x1导数:  tensor(4.)\n",
      "节点v3对x2导数:  tensor(2.)\n",
      "节点v4对x1导数:  tensor(1.2236e-06)\n",
      "节点v4对x2导数:  tensor(6.1180e-07)\n",
      "节点v5对x1导数:  tensor(3.6708e-06)\n",
      "节点v5对x2导数:  tensor(1.8354e-06)\n",
      "节点v6对x1导数:  tensor(4.8944e-06)\n",
      "节点v6对x2导数:  tensor(2.4472e-06)\n"
     ]
    }
   ],
   "source": [
    "for node_name in node_dict:\n",
    "    for var_name in var_dict:\n",
    "        node = node_dict[node_name]\n",
    "        var = var_dict[var_name]\n",
    "        \n",
    "        if var.grad is not None:\n",
    "            var.grad.zero_()\n",
    "        else:\n",
    "            var.grad = torch.tensor(0.0)\n",
    "        node.backward(retain_graph=True)\n",
    "        print(f\"节点{node_name}对{var_name}导数: \", var.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d790feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_function的值为: 2.952573776245117\n",
      "x1的导数为: 1.3894440371586825e-06\n",
      "x2的导数为: 6.947220754227601e-07\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# 自定义实现Sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "def y_function(x1, x2):\n",
    "    term1 = sigmoid(3 * sigmoid(x1 * x1 + 2 * x2 + 1))\n",
    "    term2 = sigmoid(x1 * x1 + 2 * x2 + 1)\n",
    "    return term1 + term2 + 1\n",
    "\n",
    "\n",
    "# 定义自变量x1和x2，这里假设为具体的值，可根据需要修改\n",
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# 计算y_function在x1和x2处的值\n",
    "y = y_function(x1, x2)\n",
    "\n",
    "# 计算y_function在x1和x2处的导数\n",
    "y.backward()\n",
    "\n",
    "# 输出y_function在给定x1和x2处的值和导数\n",
    "print(\"y_function的值为:\", y.item())\n",
    "print(\"x1的导数为:\", x1.grad.item())\n",
    "print(\"x2的导数为:\", x2.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5fb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def sin(x):\n",
    "    return torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fb07350",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "v5 = 3*v4\n",
    "v6 = v5 + v4 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfd78d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_function的值为: 2.952573776245117\n",
      "x1的导数为: 1.3894440371586825e-06\n",
      "x2的导数为: 6.947220754227601e-07\n"
     ]
    }
   ],
   "source": [
    "# 定义自变量x1和x2，这里假设为具体的值，可根据需要修改\n",
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# 计算y_function在x1和x2处的值\n",
    "y = y_function(x1, x2)\n",
    "\n",
    "# 计算y_function在x1和x2处的导数\n",
    "y.backward()\n",
    "\n",
    "# 输出y_function在给定x1和x2处的值和导数\n",
    "print(\"y_function的值为:\", y.item())\n",
    "print(\"x1的导数为:\", x1.grad.item())\n",
    "print(\"x2的导数为:\", x2.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e0945a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "v5 = 3*v4\n",
    "v6 = v5 + v4 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fae27230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "4.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1 ** 2 + 2 * v2 + 1\n",
    "\n",
    "# 先将x1和x2的梯度清零\n",
    "x1.grad = None\n",
    "x2.grad = None\n",
    "\n",
    "v3.backward()\n",
    "\n",
    "print(v3.item())\n",
    "print(x1.grad.item())\n",
    "print(x2.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d9fbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999996423721313\n",
      "1.2236083648531348e-06\n",
      "6.118041824265674e-07\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)\n",
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "# 先将x1和x2的梯度清零\n",
    "x1.grad = None\n",
    "x2.grad = None\n",
    "\n",
    "v4.backward()\n",
    "\n",
    "print(v4.item())\n",
    "print(x1.grad.item())\n",
    "print(x2.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd675382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9999990463256836\n",
      "3.6708252082462423e-06\n",
      "1.8354126041231211e-06\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)\n",
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "v5 = 3*v4\n",
    "# 先将x1和x2的梯度清零\n",
    "x1.grad = None\n",
    "x2.grad = None\n",
    "\n",
    "v5.backward()\n",
    "\n",
    "print(v5.item())\n",
    "print(x1.grad.item())\n",
    "print(x2.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2447e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = x1\n",
    "v2 = x2\n",
    "v3 = v1**2 + 2*v2 +1\n",
    "v4 = sigmoid(v3)\n",
    "v5 = 3*v4\n",
    "v6 = v5 + v4 +1\n",
    "node_dict = {\"v1\": v1, \"v2\": v2, \"v3\": v3,'v4':v4,'v5':v5,'v6':v6}\n",
    "var_dict = {\"x1\": x1, \"x2\": x2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "104ceeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(2., requires_grad=True)\n",
    "x2 = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b4003e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点v1对x1导数:  tensor(1.)\n",
      "节点v1对x2导数:  tensor(0.)\n",
      "节点v2对x1导数:  tensor(0.)\n",
      "节点v2对x2导数:  tensor(1.)\n",
      "节点v3对x1导数:  tensor(4.)\n",
      "节点v3对x2导数:  tensor(2.)\n",
      "节点v4对x1导数:  tensor(1.2236e-06)\n",
      "节点v4对x2导数:  tensor(6.1180e-07)\n",
      "节点v5对x1导数:  tensor(3.6708e-06)\n",
      "节点v5对x2导数:  tensor(1.8354e-06)\n",
      "节点v6对x1导数:  tensor(4.8944e-06)\n",
      "节点v6对x2导数:  tensor(2.4472e-06)\n"
     ]
    }
   ],
   "source": [
    "for node_name in node_dict:\n",
    "    for var_name in var_dict:\n",
    "        node = node_dict[node_name]\n",
    "        var = var_dict[var_name]\n",
    "        \n",
    "        if var.grad is not None:\n",
    "            var.grad.zero_()\n",
    "        else:\n",
    "            var.grad = torch.tensor(0.0)\n",
    "        node.backward(retain_graph=True)\n",
    "        print(f\"节点{node_name}对{var_name}导数: \", var.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42bfca3-89b2-4c9b-9756-1d6644d2a5c0",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8278b21-cbf2-4e6b-bc5c-b7114987f516",
   "metadata": {},
   "source": [
    "导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8052cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6f59c-251e-42f9-8e8f-934246651923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab2dcc7-0ccd-49a7-987b-79ed5ac094c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e9b16-74b2-4f44-8781-f42a7ea37aa4",
   "metadata": {},
   "source": [
    "划分数据集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42b5cf53-1c55-4410-95a0-54d8aa596098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "    train_size = 0.875, test_size = 0.125, random_state = 188\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929dbd9-417a-43ea-9c11-08e9195ed33f",
   "metadata": {},
   "source": [
    "创建逻辑斯蒂回归模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f723f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000, multi_class='ovr')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    penalty='l2',C=1.0,random_state=None, solver='lbfgs', max_iter=3000,\n",
    "    multi_class='ovr', verbose=0,\n",
    ")\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127feda-f6e9-4d7e-a1c9-6484bab20a2c",
   "metadata": {},
   "source": [
    "使用测试数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00367e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d7895-78a1-4394-9088-6bd3be1d3aab",
   "metadata": {},
   "source": [
    "评估模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fede3-db5d-4dd2-a48b-e5241d342782",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf66833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7dfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fdf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad380d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4fa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c850b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d20ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25894967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed7eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc9514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b77d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65009834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e134f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f0073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13167ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
